#!/usr/bin/env python3
"""
lionagi Async Interactive REPL
Real Python environment with async support for lionagi
"""

import asyncio
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import lionagi components
from lionagi import Branch, iModel
from pydantic import BaseModel

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘     ğŸ¦ LIONAGI ASYNC PYTHON REPL ğŸ¦                         â•‘
â•‘                                                              â•‘
â•‘     Real Python with async support for lionagi              â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… lionagi imported and ready
âœ… Your OpenAI API key loaded
âœ… Async support enabled

ğŸš€ USAGE:
â€¢ Just type lionagi code normally
â€¢ await will work automatically
â€¢ No need for async/await wrappers

ğŸ’¡ EXAMPLES TO TRY:
""")

async def main():
    """Main async function where you can use await"""
    print("""
ğŸ”¥ Ready! Try these commands:

# 1. Quick test
branch = Branch(system="You are helpful", chat_model=iModel(provider="openai", model="gpt-3.5-turbo"))
response = await branch.communicate("Say hello in 5 words")
print(response)

# 2. Python tutor
tutor = Branch(system="You are a Python expert", chat_model=iModel(provider="openai", model="gpt-3.5-turbo"))  
answer = await tutor.communicate("What are list comprehensions?")
print(answer)

# 3. Code generator
coder = Branch(system="You write clean Python code", chat_model=iModel(provider="openai", model="gpt-3.5-turbo"))
code = await coder.communicate("Write a function to check if a number is prime")
print(code)

Let's start with a quick test:
    """)
    
    # Quick test to verify everything works
    print("ğŸ§ª Running quick test...")
    branch = Branch(
        system="You are a helpful assistant. Be concise.",
        chat_model=iModel(provider="openai", model="gpt-3.5-turbo")
    )
    
    try:
        response = await branch.communicate("Say 'lionagi is working!' in a creative way")
        print(f"âœ… Success! AI says: {response}")
        print()
    except Exception as e:
        print(f"âŒ Error: {e}")
        return
    
    print("ğŸ¯ Now try your own commands:")
    print()
    
    # Interactive loop
    while True:
        try:
            # Get user input
            user_input = input("lionagi>>> ")
            
            if user_input.strip().lower() in ['exit', 'quit']:
                print("ğŸ‘‹ Goodbye!")
                break
                
            if user_input.strip() == '':
                continue
                
            # Special commands
            if user_input.strip() == 'help':
                print_help()
                continue
                
            if user_input.strip() == 'examples':
                await show_examples()
                continue
            
            # Execute the code
            try:
                # For simple expressions, use eval
                if not any(keyword in user_input for keyword in ['await', '=', 'print', 'for', 'if', 'def', 'class']):
                    result = eval(user_input)
                    if result is not None:
                        print(result)
                else:
                    # For complex code with await, exec it
                    exec(user_input)
            except SyntaxError:
                # If it has await, wrap it properly
                if 'await' in user_input:
                    try:
                        result = await eval(user_input)
                        if result is not None:
                            print(result)
                    except:
                        exec(f"result = {user_input}")
                        if 'result' in locals():
                            print(locals()['result'])
                else:
                    raise
                    
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")
            print("ğŸ’¡ Tip: Try 'help' for examples or 'examples' for working code")

def print_help():
    """Print help information"""
    print("""
ğŸ†˜ LIONAGI REPL HELP:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ BASIC COMMANDS:
â€¢ help - Show this help
â€¢ examples - Run example code
â€¢ exit/quit - Exit the REPL

ğŸš€ LIONAGI USAGE:
â€¢ Create branch: branch = Branch(system="...", chat_model=iModel(provider="openai", model="gpt-3.5-turbo"))
â€¢ Chat: response = await branch.communicate("your question")
â€¢ Print: print(response)

ğŸ’¡ TIPS:
â€¢ You can use 'await' directly
â€¢ Variables persist between commands
â€¢ Use print() to see results
    """)

async def show_examples():
    """Show working examples"""
    print("\nğŸ”¥ RUNNING EXAMPLES:")
    print("=" * 40)
    
    # Example 1: Basic chat
    print("ğŸ“ Example 1: Basic Chat")
    branch = Branch(
        system="You are a helpful assistant", 
        chat_model=iModel(provider="openai", model="gpt-3.5-turbo")
    )
    response = await branch.communicate("What's the capital of France?")
    print(f"ğŸ¤– {response}")
    print()
    
    # Example 2: Code generation  
    print("ğŸ“ Example 2: Code Generation")
    coder = Branch(
        system="You are a Python expert who writes clean, simple code",
        chat_model=iModel(provider="openai", model="gpt-3.5-turbo") 
    )
    code = await coder.communicate("Write a Python function to reverse a string")
    print(f"ğŸ’» Generated Code:\n{code}")
    print()
    
    # Example 3: Structured response
    print("ğŸ“ Example 3: Structured Response")
    
    class Summary(BaseModel):
        topic: str
        key_points: list[str]
        difficulty: str
    
    analyst = Branch(
        system="You are an expert analyst",
        chat_model=iModel(provider="openai", model="gpt-3.5-turbo")
    )
    
    result = await analyst.communicate(
        "Summarize machine learning basics", 
        response_format=Summary
    )
    
    print(f"ğŸ“Š Topic: {result.topic}")
    print(f"ğŸ¯ Key Points: {result.key_points}")
    print(f"ğŸ“ˆ Difficulty: {result.difficulty}")
    print()

if __name__ == "__main__":
    asyncio.run(main())